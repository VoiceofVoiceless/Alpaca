#the generalized accrual of data from publicly available sources.


#generated by Claude 3.7 Sonnet - Anthropic 04/17/2025
import requests
import pandas as pd
import numpy as np
import json
import time
import os
from datetime import datetime
from bs4 import BeautifulSoup
from concurrent.futures import ThreadPoolExecutor
import sqlite3
import logging

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("economic_data_scraper.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("EconomicDataScraper")

class EconomicDataScraper:
    def __init__(self, database_path="economic_data.db"):
        """Initialize the Economic Data Scraper with a database connection."""
        self.database_path = database_path
        self.create_database()
        self.sources = {
            # US Sources
            "fred": {
                "name": "Federal Reserve Economic Data (FRED)",
                "base_url": "https://api.stlouisfed.org/fred/",
                "requires_api_key": True,
                "api_key_env": "FRED_API_KEY"
            },
            "bea": {
                "name": "Bureau of Economic Analysis",
                "base_url": "https://apps.bea.gov/api/data",
                "requires_api_key": True,
                "api_key_env": "BEA_API_KEY"
            },
            "bls": {
                "name": "Bureau of Labor Statistics",
                "base_url": "https://api.bls.gov/publicAPI/v2/",
                "requires_api_key": True,
                "api_key_env": "BLS_API_KEY"
            },
            "census": {
                "name": "US Census Bureau",
                "base_url": "https://api.census.gov/data/",
                "requires_api_key": True,
                "api_key_env": "CENSUS_API_KEY"
            },
            # International Sources
            "world_bank": {
                "name": "World Bank",
                "base_url": "https://api.worldbank.org/v2/",
                "requires_api_key": False
            },
            "ecb": {
                "name": "European Central Bank",
                "base_url": "https://sdw-wsrest.ecb.europa.eu/service/",
                "requires_api_key": False
            },
            "imf": {
                "name": "International Monetary Fund",
                "base_url": "https://www.imf.org/external/datamapper/api/v1/",
                "requires_api_key": False
            },
            "oecd": {
                "name": "Organisation for Economic Co-operation and Development",
                "base_url": "https://stats.oecd.org/SDMX-JSON/data/",
                "requires_api_key": False
            }
        }
        
        self.indicators = {
            "gdp": {
                "name": "Gross Domestic Product",
                "frequency": "quarterly",
                "category": "output"
            },
            "inflation": {
                "name": "Consumer Price Index",
                "frequency": "monthly",
                "category": "prices"
            },
            "unemployment": {
                "name": "Unemployment Rate",
                "frequency": "monthly",
                "category": "labor"
            },
            "interest_rate": {
                "name": "Central Bank Interest Rate",
                "frequency": "daily",
                "category": "monetary"
            },
            "trade_balance": {
                "name": "Trade Balance",
                "frequency": "monthly",
                "category": "trade"
            },
            "debt_to_gdp": {
                "name": "Government Debt to GDP",
                "frequency": "yearly",
                "category": "fiscal"
            },
            "retail_sales": {
                "name": "Retail Sales",
                "frequency": "monthly",
                "category": "consumption"
            },
            "industrial_production": {
                "name": "Industrial Production",
                "frequency": "monthly",
                "category": "production"
            },
            "housing_starts": {
                "name": "Housing Starts",
                "frequency": "monthly",
                "category": "housing"
            },
            "stock_index": {
                "name": "Stock Market Index",
                "frequency": "daily",
                "category": "financial"
            }
        }
        
    def create_database(self):
        """Create SQLite database and tables if they don't exist."""
        conn = sqlite3.connect(self.database_path)
        cursor = conn.cursor()
        
        # Create sources table
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS sources (
            id INTEGER PRIMARY KEY,
            name TEXT NOT NULL,
            code TEXT NOT NULL UNIQUE,
            base_url TEXT NOT NULL,
            description TEXT,
            requires_api_key BOOLEAN,
            last_updated TIMESTAMP
        )
        ''')
        
        # Create indicators table
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS indicators (
            id INTEGER PRIMARY KEY,
            name TEXT NOT NULL,
            code TEXT NOT NULL,
            category TEXT,
            frequency TEXT,
            description TEXT,
            source_id INTEGER,
            FOREIGN KEY (source_id) REFERENCES sources (id),
            UNIQUE (code, source_id)
        )
        ''')
        
        # Create regions table (countries, states, etc.)
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS regions (
            id INTEGER PRIMARY KEY,
            name TEXT NOT NULL,
            code TEXT NOT NULL UNIQUE,
            region_type TEXT NOT NULL,
            parent_id INTEGER,
            FOREIGN KEY (parent_id) REFERENCES regions (id)
        )
        ''')
        
        # Create economic data table
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS economic_data (
            id INTEGER PRIMARY KEY,
            indicator_id INTEGER NOT NULL,
            region_id INTEGER NOT NULL,
            date TIMESTAMP NOT NULL,
            value REAL,
            observation_status TEXT,
            source_id INTEGER NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (indicator_id) REFERENCES indicators (id),
            FOREIGN KEY (region_id) REFERENCES regions (id),
            FOREIGN KEY (source_id) REFERENCES sources (id),
            UNIQUE (indicator_id, region_id, date, source_id)
        )
        ''')
        
        conn.commit()
        conn.close()
        logger.info("Database initialization completed")
    
    def get_api_key(self, source_code):
        """Get API key from environment variables."""
        source = self.sources.get(source_code)
        if not source:
            logger.error(f"Source {source_code} not found")
            return None
            
        if not source.get("requires_api_key", False):
            return None
            
        env_var = source.get("api_key_env")
        if not env_var:
            logger.error(f"API key environment variable not defined for {source_code}")
            return None
            
        api_key = os.environ.get(env_var)
        if not api_key:
            logger.error(f"API key not found in environment variable {env_var}")
            return None
            
        return api_key
    
    def fetch_fred_data(self, series_id, start_date=None, end_date=None):
        """Fetch data from Federal Reserve Economic Data (FRED)."""
        api_key = self.get_api_key("fred")
        if not api_key:
            return None
            
        params = {
            "series_id": series_id,
            "api_key": api_key,
            "file_type": "json"
        }
        
        if start_date:
            params["observation_start"] = start_date
        if end_date:
            params["observation_end"] = end_date
            
        url = f"{self.sources['fred']['base_url']}series/observations"
        
        try:
            response = requests.get(url, params=params)
            response.raise_for_status()
            data = response.json()
            
            # Convert to DataFrame
            if "observations" in data:
                df = pd.DataFrame(data["observations"])
                df["date"] = pd.to_datetime(df["date"])
                df["value"] = pd.to_numeric(df["value"], errors="coerce")
                return df
            else:
                logger.error(f"No observations found for series {series_id}")
                return None
                
        except requests.exceptions.RequestException as e:
            logger.error(f"Error fetching data from FRED: {e}")
            return None
    
    def fetch_world_bank_data(self, indicator, country_code="all", start_year=None, end_year=None):
        """Fetch data from World Bank API."""
        current_year = datetime.now().year
        
        if not start_year:
            start_year = current_year - 10
        if not end_year:
            end_year = current_year
        
        url = f"{self.sources['world_bank']['base_url']}countries/{country_code}/indicators/{indicator}"
        
        params = {
            "format": "json",
            "per_page": 1000,
            "date": f"{start_year}:{end_year}"
        }
        
        try:
            response = requests.get(url, params=params)
            response.raise_for_status()
            data = response.json()
            
            # World Bank API returns metadata in first position and data in second
            if len(data) > 1 and isinstance(data[1], list):
                df = pd.DataFrame(data[1])
                if not df.empty:
                    df["date"] = df["date"].astype(str)
                    df["value"] = pd.to_numeric(df["value"], errors="coerce")
                    return df
            
            logger.error(f"No data found for indicator {indicator} and country {country_code}")
            return None
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Error fetching data from World Bank: {e}")
            return None
    
    def save_data_to_db(self, data, indicator_code, source_code, region_code):
        """Save fetched data to SQLite database."""
        if data is None or data.empty:
            logger.warning(f"No data to save for indicator {indicator_code} from {source_code}")
            return 0
        
        conn = sqlite3.connect(self.database_path)
        cursor = conn.cursor()
        
        # Get or create source record
        source = self.sources.get(source_code)
        cursor.execute(
            "SELECT id FROM sources WHERE code = ?", 
            (source_code,)
        )
        source_result = cursor.fetchone()
        
        if not source_result:
            cursor.execute(
                "INSERT INTO sources (name, code, base_url, requires_api_key, last_updated) VALUES (?, ?, ?, ?, ?)",
                (source["name"], source_code, source["base_url"], source.get("requires_api_key", False), datetime.now())
            )
            source_id = cursor.lastrowid
        else:
            source_id = source_result[0]
            cursor.execute(
                "UPDATE sources SET last_updated = ? WHERE id = ?",
                (datetime.now(), source_id)
            )
        
        # Get or create indicator record
        indicator = self.indicators.get(indicator_code, {"name": indicator_code, "frequency": "unknown", "category": "other"})
        cursor.execute(
            "SELECT id FROM indicators WHERE code = ? AND source_id = ?", 
            (indicator_code, source_id)
        )
        indicator_result = cursor.fetchone()
        
        if not indicator_result:
            cursor.execute(
                "INSERT INTO indicators (name, code, category, frequency, source_id) VALUES (?, ?, ?, ?, ?)",
                (indicator.get("name", indicator_code), indicator_code, indicator.get("category"), indicator.get("frequency"), source_id)
            )
            indicator_id = cursor.lastrowid
        else:
            indicator_id = indicator_result[0]
        
        # Get or create region record
        cursor.execute("SELECT id FROM regions WHERE code = ?", (region_code,))
        region_result = cursor.fetchone()
        
        if not region_result:
            cursor.execute(
                "INSERT INTO regions (name, code, region_type) VALUES (?, ?, ?)",
                (region_code, region_code, "country" if len(region_code) <= 3 else "other")
            )
            region_id = cursor.lastrowid
        else:
            region_id = region_result[0]
        
        # Prepare data for insertion
        records_added = 0
        for _, row in data.iterrows():
            try:
                date_val = row.get("date") or row.get("observation_date")
                value_val = row.get("value")
                
                if date_val is not None and value_val is not None:
                    status_val = row.get("observation_status", "")
                    
                    cursor.execute(
                        """
                        INSERT OR REPLACE INTO economic_data 
                        (indicator_id, region_id, date, value, observation_status, source_id)
                        VALUES (?, ?, ?, ?, ?, ?)
                        """,
                        (indicator_id, region_id, date_val, value_val, status_val, source_id)
                    )
                    records_added += 1
                    
            except sqlite3.Error as e:
                logger.error(f"SQLite error while inserting data: {e}")
                continue
        
        conn.commit()
        conn.close()
        logger.info(f"Added {records_added} records for {indicator_code} from {source_code}")
        return records_added
    
    def fetch_bls_data(self, series_id, start_year=None, end_year=None):
        """Fetch data from Bureau of Labor Statistics."""
        api_key = self.get_api_key("bls")
        if not api_key:
            return None
            
        current_year = datetime.now().year
        
        if not start_year:
            start_year = current_year - 10
        if not end_year:
            end_year = current_year
            
        url = f"{self.sources['bls']['base_url']}timeseries/data/"
        
        headers = {
            "Content-Type": "application/json"
        }
        
        data = {
            "seriesid": [series_id],
            "startyear": str(start_year),
            "endyear": str(end_year),
            "registrationkey": api_key
        }
        
        try:
            response = requests.post(url, headers=headers, json=data)
            response.raise_for_status()
            data = response.json()
            
            if "Results" in data and "series" in data["Results"]:
                series_data = data["Results"]["series"]
                if series_data and "data" in series_data[0]:
                    df = pd.DataFrame(series_data[0]["data"])
                    
                    # Convert period (e.g., M01) to month number
                    if "period" in df.columns:
                        df["month"] = df["period"].str.replace("M", "").astype(int)
                    
                    # Create date column
                    if "year" in df.columns and "month" in df.columns:
                        df["date"] = pd.to_datetime(df["year"] + "-" + df["month"].astype(str) + "-01")
                    elif "year" in df.columns:
                        df["date"] = pd.to_datetime(df["year"].astype(str))
                    
                    # Convert value
                    if "value" in df.columns:
                        df["value"] = pd.to_numeric(df["value"], errors="coerce")
                    
                    return df
            
            logger.error(f"No data found for series {series_id}")
            return None
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Error fetching data from BLS: {e}")
            return None
    
    def fetch_eurostat_data(self, dataset_code, dimensions=None):
        """Fetch data from Eurostat."""
        base_url = "https://ec.europa.eu/eurostat/api/dissemination/sdmx/2.1/data/"
        url = f"{base_url}{dataset_code}"
        
        params = {
            "format": "JSON",
            "startPeriod": datetime.now().year - 10,
            "endPeriod": datetime.now().year
        }
        
        # Add dimensions if provided
        if dimensions:
            dimension_str = ""
            for dim in dimensions:
                dimension_str += f"{dim}."
            url = f"{url}/{dimension_str}"
        
        try:
            response = requests.get(url, params=params)
            response.raise_for_status()
            data = response.json()
            
            # Eurostat data structure is complex, process accordingly
            if "structure" in data and "dataSets" in data:
                # Extract dimensions
                dimensions = data["structure"]["dimensions"]["observation"]
                
                # Extract data points
                values = data["dataSets"][0]["observations"]
                
                # Process and convert to DataFrame
                # This would require further processing specific to Eurostat's structure
                return pd.DataFrame()  # Placeholder
            
            logger.error(f"No data found for dataset {dataset_code}")
            return None
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Error fetching data from Eurostat: {e}")
            return None
    
    def fetch_data(self, source_code, indicator_code, region_code="US", start_date=None, end_date=None):
        """Fetch data from the specified source for the given indicator and region."""
        if source_code == "fred":
            data = self.fetch_fred_data(indicator_code, start_date, end_date)
        elif source_code == "world_bank":
            data = self.fetch_world_bank_data(indicator_code, region_code, 
                                             start_date.year if start_date else None,
                                             end_date.year if end_date else None)
        elif source_code == "bls":
            data = self.fetch_bls_data(indicator_code,
                                      start_date.year if start_date else None,
                                      end_date.year if end_date else None)
        else:
            logger.error(f"Source {source_code} not implemented yet")
            return None
            
        return self.save_data_to_db(data, indicator_code, source_code, region_code)
    
    def fetch_all_indicators(self, source_code="fred", region_code="US"):
        """Fetch all defined indicators from a specific source."""
        results = {}
        
        for indicator_code in self.indicators:
            logger.info(f"Fetching {indicator_code} from {source_code} for {region_code}")
            records_added = self.fetch_data(source_code, indicator_code, region_code)
            results[indicator_code] = records_added
            # Sleep to avoid hitting rate limits
            time.sleep(1)
            
        return results
    
    def query_data(self, indicator_code, region_code="US", start_date=None, end_date=None, source_code=None):
        """Query stored data from the database."""
        conn = sqlite3.connect(self.database_path)
        
        query = """
        SELECT ed.date, ed.value, i.name as indicator_name, r.name as region_name, 
               s.name as source_name, ed.observation_status
        FROM economic_data ed
        JOIN indicators i ON ed.indicator_id = i.id
        JOIN regions r ON ed.region_id = r.id
        JOIN sources s ON ed.source_id = s.id
        WHERE i.code = ?
        AND r.code = ?
        """
        
        params = [indicator_code, region_code]
        
        if start_date:
            query += " AND ed.date >= ?"
            params.append(start_date)
        
        if end_date:
            query += " AND ed.date <= ?"
            params.append(end_date)
            
        if source_code:
            query += " AND s.code = ?"
            params.append(source_code)
            
        query += " ORDER BY ed.date"
        
        try:
            df = pd.read_sql_query(query, conn, params=params)
            if not df.empty and "date" in df.columns:
                df["date"] = pd.to_datetime(df["date"])
            return df
        except sqlite3.Error as e:
            logger.error(f"Error querying database: {e}")
            return None
        finally:
            conn.close()
    
    def export_data(self, indicator_code, region_code="US", output_format="csv", filename=None):
        """Export data to a file format (CSV, JSON, Excel)."""
        data = self.query_data(indicator_code, region_code)
        
        if data is None or data.empty:
            logger.warning(f"No data to export for {indicator_code} in {region_code}")
            return None
            
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
            filename = f"{indicator_code}_{region_code}_{timestamp}"
            
        if output_format.lower() == "csv":
            filename = f"{filename}.csv"
            data.to_csv(filename, index=False)
        elif output_format.lower() == "json":
            filename = f"{filename}.json"
            data.to_json(filename, orient="records", date_format="iso")
        elif output_format.lower() == "excel":
            filename = f"{filename}.xlsx"
            data.to_excel(filename, index=False)
        else:
            logger.error(f"Unsupported output format: {output_format}")
            return None
            
        logger.info(f"Exported data to {filename}")
        return filename


# Example usage
if __name__ == "__main__":
    # Set API keys in environment variables first
    # os.environ["FRED_API_KEY"] = "your-fred-api-key"
    # os.environ["BLS_API_KEY"] = "your-bls-api-key"
    # os.environ["BEA_API_KEY"] = "your-bea-api-key"
    
    scraper = EconomicDataScraper()
    
    # Example: Fetch GDP data from FRED
    scraper.fetch_data("fred", "GDP", "US")
    
    # Example: Fetch unemployment rate from BLS
    scraper.fetch_data("bls", "LNS14000000", "US")
    
    # Example: Fetch GDP data from World Bank for multiple countries
    for country in ["US", "GB", "JP", "DE", "FR"]:
        scraper.fetch_data("world_bank", "NY.GDP.MKTP.CD", country)
    
    # Query and export results
    gdp_data = scraper.query_data("GDP", "US")
    if gdp_data is not None:
        print(f"Retrieved {len(gdp_data)} GDP records")
        scraper.export_data("GDP", "US", "csv")
